{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sum.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LeeYuuuan/Graph-Kernel-Isomorphic-/blob/main/Sum.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ug1Q0ZupRTvy"
      },
      "outputs": [],
      "source": [
        "%pip install grakel\n",
        "import grakel\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import networkx.algorithms.isomorphism as iso\n",
        "import pandas as pd\n",
        "import time\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "\n",
        "import networkx.algorithms.isomorphism as iso\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from sklearn import metrics, svm\n",
        "from sklearn.preprocessing import label_binarize\n",
        "from sklearn.metrics import classification_report \n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "\n",
        "\n",
        "def draw_graphs(Gra1,Gra2):\n",
        "    pos = nx.spring_layout(Gra1)\n",
        "    pos1 = nx.spring_layout(Gra2) \n",
        "    plt.subplot(121)\n",
        "    nx.draw(Gra1, pos, with_labels=True, node_color='pink', node_size=500)\n",
        "    plt.subplot(122)\n",
        "    nx.draw(Gra2, pos1, with_labels=True, node_size=500)\n",
        "    plt.show()\n",
        "\n",
        "def GetGraphData(dataset_name):\n",
        "    dataset = grakel.datasets.fetch_dataset(dataset_name, verbose=True, data_home=None, download_if_missing=True, with_classes=True, produce_labels_nodes=False, prefer_attr_nodes=False, prefer_attr_edges=False, as_graphs=False)\n",
        "    G = dataset.data\n",
        "    y = dataset.target\n",
        "    return G, y\n",
        "\n",
        "def GetGraph(an_old_graph):\n",
        "    \"\"\"\n",
        "    This function input a graph from /grakel dataset/\n",
        "    Then converted to a type [class]Graph (networkx)\n",
        "    \"\"\"\n",
        "    Graph = nx.MultiGraph()\n",
        "    Graph.add_edges_from(list(an_old_graph[0]))\n",
        "\n",
        "    if len(an_old_graph[1]) != 0:\n",
        "      for node in an_old_graph[1]:\n",
        "        Graph.add_node(node, attr=an_old_graph[1][node])\n",
        "    if len(an_old_graph[2]) !=0:\n",
        "      for edge in an_old_graph[2]:\n",
        "        Graph.add_edge(edge[0],edge[1], attr=an_old_graph[2][edge])\n",
        "  \n",
        "    return Graph\n",
        "\n",
        "def GetGraphwithoutLabel(an_old_graph):\n",
        "    \"\"\"\n",
        "    This function input a graph from /grakel dataset/\n",
        "    Then converted to a type [class]Graph (networkx) \n",
        "    NOTE: without labels.\n",
        "    \"\"\"\n",
        "    Graph = nx.MultiGraph()\n",
        "    Graph.add_edges_from(list(an_old_graph[0]))\n",
        "\n",
        "    return Graph\n",
        "\n",
        "def GetAllGraph(graph_dataset):\n",
        "    \"\"\"\n",
        "    Get all Graph with type of [class]Graph\n",
        "    return a list [Graph1, Graph2, ...]\n",
        "    \"\"\"\n",
        "    Graphs = []\n",
        "    for graph_data in graph_dataset:\n",
        "      Graphs.append(GetGraph(graph_data))\n",
        "    \n",
        "    return Graphs\n",
        "\n",
        "def GetAllGraphwithoutLables(graph_dataset):\n",
        "    \"\"\"\n",
        "    Get all Graph with type of [class]Graph\n",
        "    return a list [Graph1, Graph2, ...]\n",
        "    \"\"\"\n",
        "    Graphs = []\n",
        "    for graph_data in graph_dataset:\n",
        "      Graphs.append(GetGraphwithoutLabel(graph_data))\n",
        "    \n",
        "    return Graphs\n",
        "\n",
        "def GetSumCount(Graphs):\n",
        "    \"\"\"\n",
        "    Get the number of the graphs in the dataset.\n",
        "    \"\"\"\n",
        "    return len(Graphs)\n",
        "\n",
        "def GetAverageNodes(Graphs):\n",
        "    \"\"\"\n",
        "    Get the average number of nodes for a certain dataset.\n",
        "    \"\"\"\n",
        "    sum = 0\n",
        "    for Graph in Graphs:\n",
        "        sum += len(Graph.nodes())\n",
        "    \n",
        "    return sum/len(Graphs)\n",
        "\n",
        "\n",
        "def GetAverageEdges(Graphs):\n",
        "    \"\"\"\n",
        "    Get the average number of edges for a certain dataset.\n",
        "    \"\"\"\n",
        "    sum = 0\n",
        "    for Graph in Graphs:\n",
        "        sum += len(Graph.edges())\n",
        "    \n",
        "    return sum/len(Graphs)/2\n",
        "\n",
        "def GetMaxandMinNode(Graphs):\n",
        "    \"\"\"\n",
        "    Get the max and min number of nodes in Graphs.\n",
        "    \"\"\"\n",
        "    max_number = - 1\n",
        "    min_number = 999999\n",
        "    for Graph in Graphs:\n",
        "        if len(Graph.nodes()) < min_number:\n",
        "            min_number = len(Graph.nodes())\n",
        "        \n",
        "        if len(Graph.nodes()) > max_number:\n",
        "            max_number = len(Graph.nodes())\n",
        "    return [max_number, min_number]\n",
        "\n",
        "\n",
        "def GetLabelCount(dataset_name):\n",
        "    \"\"\"\n",
        "    Get the number of each labels.\n",
        "    \"\"\"\n",
        "    G,y = GetGraphData(dataset_name)\n",
        "   \n",
        "    values, counts = np.unique(y, return_counts=True)\n",
        "    for i in range(len(values)):\n",
        "        print(\"label: \",values[i], \"count:\", counts[i])\n",
        "\n",
        "def GetSummary(name):\n",
        "    \"\"\"\n",
        "    Get the summary statisic information for a certain Dataset.\n",
        "\n",
        "    or Get for a list of Datasets.\n",
        "    \"\"\"\n",
        "    if type(name) == str :\n",
        "        G,y = GetGraphData(name)\n",
        "        Graphs = GetAllGraph(G)\n",
        "        df = pd.DataFrame(columns=[\"Name\",\"Graphs\",\"Class\",\"Average Nodes\", \"Average Edges\", \"Max number of nodes\", \"Min number of nodes\"])\n",
        "        temp_df = {\"Name\": name, \n",
        "                   \"Graphs\": GetSumCount(Graphs), \n",
        "                   \"Class\": len(set(y)), \n",
        "                   \"Average Nodes\": GetAverageNodes(Graphs),\n",
        "                   \"Average Edges\": GetAverageEdges(Graphs),\n",
        "                   \"Max number of nodes\": GetMaxandMinNode(Graphs)[0],\n",
        "                   \"Min number of nodes\": GetMaxandMinNode(Graphs)[1]\n",
        "                   }\n",
        "        df = df.append([temp_df], ignore_index=True)\n",
        "        # df.loc[0] = [name, GetSumCount(Graphs), len(set(y)), GetAverageNodes(Graphs)]\n",
        "    elif type(name) == list:\n",
        "        df = pd.DataFrame(columns=[\"Name\",\"Graphs\",\"Class\",\"Average Nodes\", \"Average Edges\", \"Max number of nodes\", \"Min number of nodes\"])\n",
        "        for dataset in name:\n",
        "            G,y = GetGraphData(dataset)\n",
        "            Graphs = GetAllGraph(G)\n",
        "            \n",
        "            temp_df = {\"Name\": dataset, \n",
        "                   \"Graphs\": GetSumCount(Graphs), \n",
        "                   \"Class\": len(set(y)), \n",
        "                   \"Average Nodes\" : GetAverageNodes(Graphs),\n",
        "                   \"Average Edges\" : GetAverageEdges(Graphs),\n",
        "                   \"Max number of nodes\": GetMaxandMinNode(Graphs)[0],\n",
        "                   \"Min number of nodes\": GetMaxandMinNode(Graphs)[1]\n",
        "                   }\n",
        "            df = df.append(temp_df, ignore_index=True)\n",
        "    return df\n",
        "\n",
        "def IsIsomorphicDefault(G1,G2,is_node_labeled,is_edge_labeled):\n",
        "  \"\"\"\n",
        "  Input two Graphs G1, G2,\n",
        "  Input True/False if Node/edge is labeled or not.\n",
        "\n",
        "  return True/False if two Graphs is isomorphic or not.\n",
        "  \"\"\"\n",
        "  if is_node_labeled:\n",
        "    nm = iso.numerical_node_match(\"attr\",0)\n",
        "    if is_edge_labeled:\n",
        "      em = iso.numerical_edge_match(\"attr\",-1)\n",
        "      GM = iso.GraphMatcher(G1, G2, node_match=nm, edge_match=em)\n",
        "    else:\n",
        "      GM = iso.GraphMatcher(G1, G2, node_match=nm)\n",
        "  else:\n",
        "    if is_edge_labeled:\n",
        "      em = iso.numerical_edge_match(\"attr\",-1)\n",
        "      GM = iso.GraphMatcher(G1, G2, edge_match=em)\n",
        "    else:\n",
        "      GM = iso.GraphMatcher(G1, G2)\n",
        "  \n",
        "  return np.float64(GM.is_isomorphic())\n",
        "\n",
        "\n",
        "def CreateFeatureMatrix(graphs,is_node_labeled,is_edge_labeled):\n",
        "    feature_matrix = np.zeros([len(graphs),len(graphs)])\n",
        "    for i in range(len(graphs)):\n",
        "      for j in range(len(graphs)):\n",
        "        feature_matrix[i,j] = IsIsomorphicDefault(graphs[i],graphs[j],is_node_labeled,is_edge_labeled)\n",
        "   \n",
        "  \n",
        "    return feature_matrix\n",
        "\n",
        "def GetIsomorphicFeatureMatrix(dataset_name,is_node_labeled,is_edge_labeled):\n",
        "    G, y = GetGraphData(dataset_name)\n",
        "    all_graph = GetAllGraph(G)\n",
        "    return CreateFeatureMatrix(all_graph,is_node_labeled,is_edge_labeled), y\n",
        "  \n",
        "\n",
        "def DrawIsomorphicMatrix(dataset_name, is_node_labeled, is_edge_labeled):\n",
        "    sumIso = 0\n",
        "    fm, y = GetIsomorphicFeatureMatrix(dataset_name,is_node_labeled,is_edge_labeled)        \n",
        "    plt.matshow(fm)\n",
        "    print(\"there are \",(np.sum(fm) - fm.shape[0])/2, \"pairs of graphs isomorphiced\" )\n",
        "\n",
        "\n",
        "def GetNodeDistribution(dataset_name):\n",
        "    \"\"\"\n",
        "    draw the node distribution histogram.\n",
        "    \"\"\"\n",
        "    G,y = GetGraphData(dataset_name)\n",
        "    Graphs = GetAllGraph(G)\n",
        "    node_count = []\n",
        "\n",
        "    for graph in Graphs:\n",
        "        node_count.append(len(graph.nodes()))\n",
        "    \n",
        "\n",
        "    label_bins = len(np.unique(y))\n",
        "\n",
        "    max_nodes = GetMaxandMinNode(Graphs)[0]\n",
        "    print(\"VISUALIZATIONS:\\nMax nodes in consideration: {}\".format(max_nodes))\n",
        "    plt.figure(figsize=(12, 5))\n",
        "    plt.subplot(121)\n",
        "    \n",
        "    plt.hist(node_count, bins=len(np.unique(node_count)))\n",
        "    plt.xlabel('Number of Nodes in Graph', fontsize=12)\n",
        "    plt.ylabel('Count', fontsize=12)\n",
        "\n",
        "    plt.subplot(122)\n",
        "    plt.hist2d(y, node_count, bins=[label_bins, 20])\n",
        "    plt.xlabel(r'Graph label', fontsize=12)\n",
        "    plt.ylabel(r'Graph size (number of nodes)', fontsize=12)\n",
        "    plt.colorbar()\n",
        "    plt.show()\n",
        "    \n",
        "    print(\"Correlation between graph size (number of nodes) and labels: %.2f\" % np.corrcoef(y, node_count)[0,1])\n",
        "\n",
        "\n",
        "def CreateFeatureMatrix_wl_test(vector_all):\n",
        "  feature_matrix = np.zeros([len(vector_all),len(vector_all[0])])\n",
        "  for i in range(len(vector_all)):\n",
        "      feature_matrix[i,:] = vector_all[i]\n",
        "      #feature_matrix[i,j] = IsIsomorphicDefault(graphs[i],graphs[j],is_node_labeled,is_edge_labeled)\n",
        "   \n",
        "  return feature_matrix\n",
        "\n",
        "def Classification(dataset_name, kernel_name):\n",
        "    G, y = GetGraphData(dataset_name)\n",
        "    G_train, G_test, y_train, y_test = train_test_split(G, y, test_size=0.1, random_state=42)\n",
        "\n",
        "    C_grid = (10. ** np.arange(-4,6,1) / len(G)).tolist()\n",
        "    if kernel_name == \"weisfeiler_lehman\":\n",
        "\n",
        "        gk = grakel.GraphKernel(kernel=[{\"name\": \"weisfeiler_lehman\", \"n_iter\": 5}, \"subtree_wl\"] ,Nystroem=20)\n",
        "        K_train = gk.fit_transform(G_train)\n",
        "        K_test = gk.transform(G_test)\n",
        "\n",
        "        clf = SVC(kernel='linear')\n",
        "        clf.fit(K_train, y_train)\n",
        "        SVC(kernel='linear')\n",
        "        C_grid = (10. ** np.arange(-4,6,1) / len(G)).tolist()\n",
        "        scores = cross_val_score(clf, K_train, y_train, cv=5)\n",
        "        y_pred = clf.predict(K_test)\n",
        "        print(str(round(accuracy_score(y_test, y_pred)*100, 2)), \"%\")\n",
        "      \n",
        "    \n",
        "    if kernel_name == \"ShortestPath\":\n",
        "        estimator = make_pipeline(\n",
        "        grakel.kernels.ShortestPath(normalize=True),\n",
        "        GridSearchCV(SVC(kernel='precomputed'), dict(C=C_grid),\n",
        "                    scoring='accuracy', cv=10))\n",
        "        \n",
        "        n_folds = 10\n",
        "        cvp = cross_val_predict(estimator, G, y, cv=n_folds)\n",
        "        acc = accuracy_score(y, cvp)\n",
        "        print(\"Accuracy:\", str(round(acc*100, 2)) + \"%\")\n",
        "        print(classification_report(y,cvp))\n",
        "\n",
        "        # sns.heatmap(cm,cmap = sns.color_palette(\"Blues\"),annot = True\n",
        "\n",
        "\n",
        "\n",
        "def IsomorphicClassification(dataset_name,label_n):\n",
        "    \n",
        "    \n",
        "\n",
        "    f_m, y = GetIsomorphicFeatureMatrix(dataset_name,label_n,False)\n",
        "\n",
        "    G_train, G_test, y_train, y_test = train_test_split(f_m, y, test_size=0.1, random_state=42)\n",
        "    clf = SVC(kernel='linear')\n",
        "    clf.fit(G_train, y_train)\n",
        "    SVC(kernel='linear')\n",
        "    y_pred = clf.predict(G_test)\n",
        "    print(classification_report(y_test, y_pred))\n",
        "\n",
        "\n",
        "\n",
        "def IsomorphicClassification(dataset_name,label_n):\n",
        "    \n",
        "    \n",
        "\n",
        "    f_m, y = GetIsomorphicFeatureMatrix(dataset_name,label_n,False)\n",
        "\n",
        "    G_train, G_test, y_train, y_test = train_test_split(f_m, y, test_size=0.1, random_state=42)\n",
        "    clf = SVC(kernel='linear')\n",
        "    clf.fit(G_train, y_train)\n",
        "    SVC(kernel='linear')\n",
        "    y_pred = clf.predict(G_test)\n",
        "    print(classification_report(y_test, y_pred))\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ]
}